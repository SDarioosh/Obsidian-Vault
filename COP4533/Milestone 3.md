
Here is a complete 8-minute presentation script based on your provided files and instructions, tailored for your two-person team.

This script is structured to follow your contributions as listed in your reports (Sean: 1, 3, 4A; Shahyah: 2, 4B, 5) and places the required focus on Algorithms 2, 4, and 5.

---

### ðŸŽ¬ Video Presentation Script (8 Minutes)

**Speakers:**

- **Sean:**Â Member 1
    
- **Shahyah:**Â Member 2
    

---

#### Section 1: Introduction & Contributions (1 minute)

**(Speaker: Sean)**

> "Hello everyone, I'm Sean."

**(Speaker: Shahyah)**

> "And I'm Shahyah. This is our final project presentation for 'Maximum Value Vault Selection.'Â "

**(Speaker: Sean)**

> "Our project's goal was to solve a problem: givenÂ `n`Â vaults, each with a specific value, we needed to find the subset of vaults that gives the maximum total value. The main constraint is that no two chosen vaults can be withinÂ `k`Â positions of each other.
> 
> We designed, implemented, and tested five different algorithms, from simple greedy heuristics to fully optimized dynamic programming solutions."

**(Speaker: Shahyah)**

> "As for our team's contributions:Â *Â **Sean**Â focused on Algorithm 1, the brute-force recursive Algorithm 3, and the top-down memoized version, 4A.Â *Â **I**Â (Shahyah) focused on the two-pointer greedy Algorithm 2, the bottom-up Algorithm 4B, and the optimized linear-time Algorithm 5.Â 
> 
> Today, we'll walk through our findings for all five, with a special focus on Algorithms 2, 4, and 5."

---

#### Section 2: The Heuristics & Brute Force (Algorithms 1, 2, 3) (2.5 minutes)

**(Speaker: Sean)**

> "First, we'll briefly cover our baseline algorithms.
> 
> **Algorithm 1**Â was a simple, right-to-left greedy approach.Â It assumes the best vault is at the end, so it starts at indexÂ `n-1`, 'takes' that vault, and then jumpsÂ `k+1`Â steps to the left, repeating this process. It's linear,Â O(n), but as it shows in our report 'Plot 9', it'sÂ **not optimal**Â for the general problem.Â 
> 
> To find aÂ _correct_Â answer, we implementedÂ **Algorithm 3**, which is a brute-force recursive solution.Â As you can see inÂ `program3.py`, theÂ `solve(i)`Â function recursively explores two choices for every vault:Â 1.Â Â **Skip**Â the vault and solve forÂ `i+1`, orÂ 2.Â Â **Take**Â the vault, add its value, and jump to solve forÂ `i+k+1`.Â 
> 
> While this is correct, it has anÂ **exponential runtime ofÂ O(2n)**Â because it recalculates the same subproblems over and over.Â You can see in our report's 'Plot 3' that it's unusable for even small inputs.Â "

**(Speaker: Shahyah)**

> "That brings us toÂ **Algorithm 2**, which was our second greedy attempt. This one required more focus.
> 
> *Â **Design:**Â I implemented aÂ **two-pointer greedy approach**, which you can see inÂ `program2.py`.Â One pointer starts at theÂ `left`Â (index 0) and the other at theÂ `right`Â (indexÂ `n-1`).Â 
> 
> - **Logic:**Â In each step of theÂ `while`Â loop, it comparesÂ `values[left]`Â andÂ `values[right]`.Â It 'takes' the vault with theÂ **larger value**, adds it to the total, and moves that specific pointer inward byÂ `k+1`Â steps.Â 
>     
> - **Analysis (Analysis 2):**Â Like Algorithm 1,Â Since the pointers only move towards the center, it's a linearÂ **O(n)**Â algorithm.Â 
>     
> - **Correctness:**Â However, despite being a 'smarter' heuristic, it isÂ **still not optimal**. A greedy choice at one end can prevent a better combination of vaults later.
>     
> 
> So, both of ourÂ O(n)Â greedy algorithms were fast but incorrect. And our one correct algorithm was exponentially slow. To get both speed and correctness, we had to use dynamic programming."

---

#### Section 3: Dynamic Programming (Algorithms 4 vs. 5) (3 minutes)

**(Speaker: Sean)**

> "To fix the exponential runtime of Algorithm 3, we developedÂ **Algorithm 4**, which uses dynamic programming to store and reuse subproblem results.Â 
> 
> I implemented the top-down version,Â **4A**, which is just the recursive Algorithm 3 but with aÂ `memo`dictionary to store results. As you can see inÂ `program4A.py`, this required us to increase Python's recursion limit just to run."

**(Speaker: Shahyah)**

> "And I implemented the bottom-up version,Â **4B**.Â This algorithm fills a DP table iteratively,Â `var1`, using the same core recurrence: the max value at any vaultÂ `i`Â is the maximum ofÂ _skipping_Â it (getting the value fromÂ `i+1`) orÂ _selecting_Â it (gettingÂ `values[i]`Â plus the value fromÂ `i+k+1`).Â 
> 
> Both 4A and 4B find the correct, optimal answer.Â **But they are not linear.**Â This brings us to the most important contrast of our project.

**(Speaker: Shahyah)**

> "Let's contrastÂ **Algorithm 4 vs. Algorithm 5**. Both are correct DP solutions, but they have different time complexities because ofÂ _how they reconstruct the path_.
> 
> - **In Algorithm 4 (4B)**, as you can see inÂ `program4B.py`, we stored theÂ _entire path_Â (the list of indices) inside the DP table atÂ _every single step_.
>     
> - The lineÂ `selectPath += path[i + k + 1]`Â performs list concatenation. In the worst case, this copy operation takesÂ O(n)Â time.Â * Since thisÂ O(n)Â operation isÂ _inside_Â our mainÂ O(n)Â loop, the total time complexity for Algorithm 4 becomesÂ **O(n2)**.Â 
>     
> 
> *Â **Algorithm 5**Â is our fully optimizedÂ **Î˜(n)**Â solution.Â 
> 
> - The key difference is inÂ `program5.py`. Instead of storing entire lists, we only store the maxÂ _value_Â in theÂ `var1`Â array.
>     
> - To build the path, we use a separateÂ `pointer`Â array.Â At each stepÂ `i`, we just store aÂ _single integer_Â (anÂ O(1)Â operation) pointing to the index we came from (`i-1`Â if we skipped, orÂ `i-k-1`Â if we took).Â *Â _After_Â theÂ O(n)Â loop is finished, we run one finalÂ O(n)Â backward pass, just following the pointers to rebuild the final path.Â 
>     
> 
> So, the total time isÂ O(n)+O(n), which isÂ Î˜(n). The lesson was that a small change in pathingâ€”from list copying to back-pointersâ€”was the difference between a quadratic and a linear algorithm."

---

#### Section 4: Implementation Demo (1.5 minutes)

**(Speaker: Shahyah)**

> "Now, I'll give a quick demo to prove this works. All our code is in standard Python.
> 
> **(Shares screen with a terminal/IDE)**
> 
> "Here is a simple test case:Â `n=4`,Â `k=1`, andÂ `values = [1, 100, 101, 1]`. The clear optimal solution is to take vault 1 (value 1) and vault 3 (value 101), for a total ofÂ **102**.
> 
> First, let's run our 'smart' greedyÂ **Algorithm 2**."
> 
> Bash
> 
> ```
> (echo 4 1; echo 1 100 101 1) | python program2.py
> ```
> 
> > **Output:**Â `101`Â `2`Â `4`Â "As you can see, Algorithm 2 fails. It picks 100 and 1 for a total of 101. It'sÂ **incorrect**.
> 
> Now, let's run theÂ O(n2)Â **Algorithm 4B**."
> 
> Bash
> 
> ```
> (echo 4 1; echo 1 100 101 1) | python program4B.py
> ```
> 
> > **Output:**Â `102`Â `1`Â `3`Â "Algorithm 4B gets theÂ **correct**Â answer.
> 
> Finally, ourÂ O(n)Â **Algorithm 5**."
> 
> Bash
> 
> ```
> (echo 4 1; echo 1 100 101 1) | python program5.py
> ```
> 
> > **Output:**Â `102`Â `1`Â `3`Â "Algorithm 5 also gets theÂ **correct**Â answer. The demo shows that 4 and 5 are correct, but 2 is not. The plots will now show the speed difference."

---

#### Section 5: Experimental Results (1 minute)

**(Speaker: Sean)**

> "Looking at our experimental plots from the report, the difference becomes obvious.
> 
> **(Show 'Plot 7: Performance Comparison of All Algorithms')**
> 
> "This plot tells the whole story.Â * The blue line,Â **Program 3 (Recursive)**, is so slow it's just a dot at the origin; it couldn't handle the large input sizes.Â 
> 
> - The orange and green lines areÂ **Program 4A and 4B**.Â You can see they have a distinctÂ _curve_, which visually confirms ourÂ O(n2)Â analysis.Â Our 'Plot 8' also confirmed that the bottom-up 4B was consistently faster than the recursive 4A due to function call overhead.Â 
>     
> - And finally, theÂ **red line is Program 5**.Â It is clearly the fastest, with a straight, linear slope.Â This plot is the practical proof that ourÂ O(n)Â optimization was successful."
>     

---

#### Section 6: Conclusion & Learning Experience (30 seconds)

**(Speaker: Shahyah)**

> "In conclusion, this project was a fantastic learning experience.Â We saw that greedy algorithms are fast but unreliable, and brute force is correct but unusable.
> 
> But the biggest takeaway, as I mentioned in my report, was the challenge of optimizing from Algorithm 4 to 5.Â It taught us that the algorithm design isn't finished at the recurrence.Â A small implementation detailâ€”like list concatenationÂ versus back-pointersÂ â€”can be the critical difference between a slow quadratic algorithm and a fast, scalable linear one."

**(Speaker: Sean)**

> "Thank you for watching."